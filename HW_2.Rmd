---
title: "HomeWork_2"
author: "Ekaterina Fokina"
date: "2022-10-26"
output:
  html_document:
    style: style.css
    keep_md: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Загрузим данные и необходимые пакеты (№1)

```{r, message=FALSE, warning=FALSE}
insurance <- read.csv("insurance_cost.csv")
summary(insurance)

library(dplyr)
library(ggplot2)
library(plotly)
library(ggbiplot)
library(ggpubr)
library(corrplot)
library(corrr)
library(fastDummies)
library(factoextra)
library(pheatmap)
library(FactoMineR)
library(devtools)
```

#График ИМТ-траты в plotly (№2)

```{r, message=FALSE, warning=FALSE, eval=FALSE}

plot_ly(
  data = insurance,
  x = ~ bmi,
  y = ~ charges,
  color = ~ smoker)

```

# А теперь в ggplotly (№3)

```{r, eval=FALSE}
plot <- insurance %>%
  ggplot(aes(x = bmi, y = charges, color = smoker)) +
  geom_point(size = 1.5) +
  theme_light()

ggplotly(plot)
```

# Корреляционный анализ (№4)

```{r, warning=FALSE}
insurance_for_cor <- insurance %>%
  select(is.integer | is.numeric)

insurance_cor <- cor(insurance_for_cor)
insurance_cor
```

## Визуализируем матрицу

```{r}
corrplot(insurance_cor, method = "color", order = "alphabet", type = "upper")
```

## И другим способом

```{r}
corrplot.mixed(insurance_cor, lower = "color", upper = "pie", order = "AOE")
```

## И ещё одним

```{r}
insurance_cor %>%
  rplot()
```

# Поработаем с датафреймом (№5)

```{r}
# Отберем все номинативные переменные и превратим их в бинарные и удалим оригинальные колонки из датафрейма

new_insurance <- dummy_cols(insurance, select_columns = c("sex", "smoker", "region"), remove_selected_columns = TRUE)

```

# Иерархическая классификация (№6)

```{r, warning=FALSE}
# Стандартизуем значения переменных

insurance_scaled <- scale(new_insurance)
head(insurance_scaled)

# И найдем дистанции

insurance_dist <- dist(insurance_scaled, method = "euclidean")
as.matrix(insurance_dist)[1:6, 1:6]

# Высчитываем дендрограмму

insurance_hc <- hclust(d = insurance_dist, 
                        method = "ward.D2")

# И визуализируем

fviz_dend(insurance_hc, cex = 0.1)

```

# Пробуем строить кластеризацию иначе (№7)

```{r, warning=FALSE}
fviz_dend(insurance_hc, k = 3, 
          cex = 0.1,
          k_colors = c("#FF99FF", "#33FF99", "#00CCFF"),
          color_labels_by_k = TRUE,
          type = "circular"
)

clusters <- cutree(insurance_hc, k = 3)

fviz_cluster(list(data = insurance_scaled, cluster = clusters),
             palette = c("#FF99FF", "#33FF99", "#00CCFF"),
             ellipse.type = "convex", 
             repel = TRUE, 
             show.clust.cent = FALSE, 
             ggtheme = theme_light())
```

# Heatmap + иерархическая кластеризация (№8)

```{r}
pheatmap(insurance_scaled)
```

# Проведем анализ данных new_insurance методом PCA

```{r}
insurance_pca <- prcomp(new_insurance, scale = T)

summary(insurance_pca)
```

Из полученных результатов видно, что 50% вариации данных объяснятся первыми тремя переменными. Посмотрим на это на графике:

```{r}
fviz_eig(insurance_pca, 
         addlabels = T, 
         ylim = c(0, 30)) +
  ggtitle("Как разные компоненты объясняют вариативность данных") +
  labs(x = "Измерения", y= "Процент объясненной вариативности") +
  theme_light() +
  theme(text = element_text(size = 10), plot.title = element_text(hjust = 0.5, size = 10))
```

Посмотрим распределение переменных относительно pc1 и pc2:

```{r}
fviz_pca_var(insurance_pca, col.var = "contrib")
```

Из графика видно, что переменные *sex_male* и *sex_female* направлены строго противоположно, что логично, так как это несовместные события. То же справедливо и для переменных *smoker_yes* и *smoker_no*. Помимо этого, образовалась группа из переменных *charges* и *smoker_yes*. Переменные регионов проживания образовали тесную группу, сосредоточенную у центра окружности. Иными словами, регион проживания вносит незначительный вклад в анализируемые главные компоненты.

Чтобы немного почистить график, оставим только топ 5 самых важных переменных:

```{r}
fviz_pca_var(insurance_pca, 
             select.var = list(contrib = 5), 
             col.var = "contrib")
```

Чтобы понять, что стоит за pc1, pc2 и pc3, построим графики:

```{r}
fviz_contrib(insurance_pca, choice = "var", axes = 1, top = 12)
fviz_contrib(insurance_pca, choice = "var", axes = 2, top = 12)
fviz_contrib(insurance_pca, choice = "var", axes = 3, top = 12)
```

Таким образом, переменная *smoker* хорошо кластериует наблюдения в оригинальном датасете. Аналогично можно судить о переменной *sex*.

И построим график ggbiplot, чтобы на нем одновременно изобразить переменные и наблюдения:

```{r}
ggbiplot(insurance_pca, 
         scale = 0, alpha = 0.1) + 
  theme_light()
```

*Мне захотелось визуализировать кластеризацию по полу и статусу курильщика*

```{r}
ggbiplot(insurance_pca, 
         scale=0, 
         groups = as.factor(insurance$sex), 
         ellipse = T,
         alpha = 0.2) +
  theme_light()

ggbiplot(insurance_pca, 
         scale=0, 
         groups = as.factor(insurance$smoker), 
         ellipse = T,
         alpha = 0.2) +
  theme_light()
```


# Проведем кластеризацию по возрасту (№10)

```{r}
# Создадим сначала переменную age_group
new_insurance_age <- new_insurance %>%
  mutate(age_group = case_when(
    age < 26 ~ "18-25",
    age >= 26 & age < 41 ~ "26-40",
    age >= 41 & age < 56 ~ "41-55",
    age >= 56 ~ "56-65"
  ))

ggbiplot(insurance_pca, 
         scale=0, 
         groups = as.factor(new_insurance_age$age_group), 
         ellipse = T,
         alpha = 0.2) +
  theme_light()
```

# Добавим еще номинативные переменные

```{r}
# Создадим переменную any_child, которая будет рассказывать о том, есть ли у человека хотя бы один ребенок
new_insurance_children <- new_insurance %>%
  mutate(any_child = as.character(ifelse(children >= 1, "Yes", "No")))

ggbiplot(insurance_pca, 
         scale=0, 
         groups = as.factor(new_insurance_children$any_child), 
         ellipse = T,
         alpha = 0.2) +
  theme_light()
```

```{r}
# Создадим переменную, которая разобьет субъектов на группы в соответствии с тем, является ли их масса тела недостаточной, избыточной или нормальной

new_insurance_bmi <- new_insurance %>%
  mutate(bmi_group = case_when(
    bmi < 18.5 ~ "underweight",
    bmi >= 18.5 & bmi < 25 ~ "normal",
    bmi >= 25 ~ "overweight"
  ))

ggbiplot(insurance_pca, 
         scale=0, 
         groups = as.factor(new_insurance_bmi$bmi_group), 
         ellipse = T,
         alpha = 0.2) +
  theme_light()
```

# Попробуем "поиграть" с данными, чтобы поднять качество анализа (№12)

## Эксперимент №1

Первая моя мысль - убрать из оригинального датафрейма очевидно кластеризующие переменные *sex* и *smoker* и посмотреть, что из этого получится.

```{r}
new_insurance_12_dummy <- dummy_cols(insurance, select_columns = c("region"), remove_selected_columns = TRUE)

new_insurance_12 <- new_insurance_12_dummy %>% select(where(is.numeric))

insurance_12_pca <- prcomp(new_insurance_12, scale = T) # Посчитаем PCA

summary(insurance_12_pca)

fviz_eig(insurance_12_pca, 
         addlabels = T, 
         ylim = c(0, 30)) +
  ggtitle("Как разные компоненты объясняют вариативность данных") +
  labs(x = "Измерения", y= "Процент объясненной вариативности") +
  theme_light() +
  theme(text = element_text(size = 10), plot.title = element_text(hjust = 0.5, size = 10))

fviz_pca_var(insurance_12_pca, col.var = "contrib") +
  ggtitle("Переменные - PCA") +
  theme_light() +
  theme(text = element_text(size = 10), plot.title = element_text(hjust = 0.5, size = 10))# Посмотрим, как выглядит график с нынешними переменными

# Отношение переменных к главным компонентам:
fviz_contrib(insurance_12_pca, choice = "var", axes = 1, top = 12)
fviz_contrib(insurance_12_pca, choice = "var", axes = 2, top = 12)
fviz_contrib(insurance_12_pca, choice = "var", axes = 3, top = 12)

ggbiplot(insurance_12_pca, 
         scale=0, 
         groups = as.factor(insurance$region), 
         ellipse = T,
         alpha = 0.2) +
  theme_minimal() # Визуализируем полученную кластеризацию
```

Из полученных данных можно судить о том, что сила кластеризации по полу и статуса курильщика была настолько высокой, что мы не могли увидеть, что наблюдения можно разделить и по регионам.

## Эксперимент №2

Раз уж начали играть с ИМТ, давайте переведем нашу номинативную переменную *bmi_group* в дамми.
(А пол и статус курильщика возвращать не будем)


```{r}
insurance_bmi <- insurance %>%
  mutate(bmi_group = case_when(
    bmi < 18.5 ~ "underweight",
    bmi >= 18.5 & bmi < 25 ~ "normal",
    bmi >= 25 ~ "overweight"
  ))

new_insurance_12_dummy_1 <- dummy_cols(insurance_bmi, select_columns = c("bmi_group", "region"), remove_selected_columns = TRUE)

new_insurance_12_1 <- new_insurance_12_dummy_1 %>% select(where(is.numeric)) 

new_insurance_12_1$bmi <- NULL

insurance_12_1_pca <- prcomp(new_insurance_12_1, scale = T) # Посчитаем PCA

summary(insurance_12_1_pca)

fviz_eig(insurance_12_1_pca, 
         addlabels = T, 
         ylim = c(0, 30)) +
  ggtitle("Как разные компоненты объясняют вариативность данных") +
  labs(x = "Измерения", y= "Процент объясненной вариативности") +
  theme_light() +
  theme(text = element_text(size = 10), plot.title = element_text(hjust = 0.5, size = 10))

fviz_pca_var(insurance_12_1_pca, col.var = "contrib") +
  ggtitle("Переменные - PCA") +
  theme_light() +
  theme(text = element_text(size = 10), plot.title = element_text(hjust = 0.5, size = 10))# Посмотрим, как выглядит график с нынешними переменными

# Отношение переменных к главным компонентам:
fviz_contrib(insurance_12_1_pca, choice = "var", axes = 1, top = 12)
fviz_contrib(insurance_12_1_pca, choice = "var", axes = 2, top = 12)
fviz_contrib(insurance_12_1_pca, choice = "var", axes = 3, top = 12)

ggbiplot(insurance_12_1_pca, 
         scale=0, 
         groups = as.factor(new_insurance_bmi$bmi_group), 
         ellipse = T,
         alpha = 0.2) +
  theme_minimal()
```

Не так выразительно, как в прошлом примере, но видно, что ИМТ тоже может стать переменной, по которой можно провести кластеризацию.
Мне кажется, что это довольно явно показывает, что манипулируя данными, можно сильно влиять на результат PCA. 

А если к этому графику добавить группировку по возрастной группе, получится красивый серпантин:

```{r}
ggbiplot(insurance_12_1_pca, 
         scale=0, 
         groups = as.factor(new_insurance_age$age_group), 
         ellipse = T,
         alpha = 0.2) +
  theme_minimal()
```

Дамми-переменная позволяет, во-первых, включить в анализ категориальную переменную. А во-вторых (как в случае с ИМТ) - позволяет искусственно создавать подвыборки для количественных переменных и смотреть, насколько это разделение может повлиять на кластеризацию.

*Прим. авт. - В случае с игрой в группы по ИМТ мне видится в этом какая-то искусственная кластеризация. Как будто, мы разделили людей, а потом увидели, что модель учла наше разделение при построении графика. Как будто тут что-то не то.*